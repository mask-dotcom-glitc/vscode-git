{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_large_file(file_path):\n",
    "    \"\"\"파일에서 텍스트를 읽어 리스트로 반환.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(chunk):\n",
    "    \"\"\"주어진 텍스트 조각에 대해 유사도를 계산.\"\"\"\n",
    "    indices, texts = chunk\n",
    "    vectorizer = TfidfVectorizer().fit_transform(texts)\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    results = []\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            if similarity_matrix[i, j] > 0.8:  # 유사도가 0.8 이상인 경우\n",
    "                results.append((indices[i], indices[j], similarity_matrix[i, j]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_chunks(file_path, chunk_size):\n",
    "    \"\"\"파일을 청크 단위로 분할.\"\"\"\n",
    "    texts = read_large_file(file_path)\n",
    "    num_texts = len(texts)\n",
    "    chunks = [\n",
    "        (list(range(i, min(i + chunk_size, num_texts))),\n",
    "         texts[i:min(i + chunk_size, num_texts)])\n",
    "        for i in range(0, num_texts, chunk_size)\n",
    "    ]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chunk_size(file_path, chunk_sizes):\n",
    "    \"\"\"다양한 청크 크기에 대해 실행 시간을 측정.\"\"\"\n",
    "    results = []\n",
    "    for chunk_size in chunk_sizes:\n",
    "        print(f\"Testing chunk size: {chunk_size}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 청크 생성\n",
    "        chunks = process_in_chunks(file_path, chunk_size)\n",
    "\n",
    "        # 멀티프로세싱을 통한 유사도 계산\n",
    "        with Pool() as pool:\n",
    "            pool.map(calculate_similarity, chunks)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Chunk size {chunk_size}: {elapsed_time:.2f} seconds\")\n",
    "        results.append((chunk_size, elapsed_time))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing chunk size: 100\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = 'AI 도입효과2.txt'  # 입력 텍스트 파일 경로\n",
    "    chunk_sizes = [100, 500, 1000, 2000, 5000, 10000]  # 테스트할 청크 크기 목록\n",
    "\n",
    "    # 청크 크기별 실행 시간 측정\n",
    "    results = test_chunk_size(input_file, chunk_sizes)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"\\nPerformance Results:\")\n",
    "    for chunk_size, elapsed_time in results:\n",
    "        print(f\"Chunk size {chunk_size}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # 결과 시각화\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        chunk_sizes, times = zip(*results)\n",
    "        plt.plot(chunk_sizes, times, marker='o')\n",
    "        plt.xlabel('Chunk Size')\n",
    "        plt.ylabel('Execution Time (seconds)')\n",
    "        plt.title('Chunk Size vs Execution Time')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"Matplotlib is not installed. Skipping visualization.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
